{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3d27ab0",
   "metadata": {},
   "source": [
    "## Latent Semantic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1335d2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import codecs\n",
    "\n",
    "corpus_path = \"news-corpus//\"\n",
    "article_paths = [os.path.join(corpus_path,p) for p in os.listdir(corpus_path)]\n",
    "\n",
    "doc_complete = []\n",
    "for path in article_paths:\n",
    "    with open(path, 'rb') as f:\n",
    "        doc_content = f.read().decode(errors='ignore')\n",
    "        doc_complete.append(doc_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "570d8dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc_complete[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ef129c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "for i in range(len(doc_complete)):\n",
    "    doc_complete[i] = re.sub(r'[^\\w\\s.]', '', doc_complete[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb00adf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc_complete[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54c40ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "133f9e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_summaries = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d22391d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for Document 1\n",
      "\n",
      "\n",
      "At a time when the two extremes of malnourishment and obesity plague large portions of the world India has taken it upon herself to educate the masses about these smallseeded grasses that are highly beneficial to human health.Millet and grain cereals despite being rich sources of protein and antioxidants with high nutritional value have never been considered fashionable foods however India has done remarkably well when it has come to meeting the caloric needs and demands of her people.India the worlds largest producer and the worlds secondlargest exporter of millet are hoping to change the humble millets reputation worldwide.Unlike a large part of the rest of the world almost every Indian household is acquainted with the taste and the benefits of millet.Millets have been a staple of the Indian diet especially in rural India for years and remain prevalent even today.\n",
      "We grow several types of Shri Anna Millets such as Shri Anna Jowar Shri Anna Ragi Shri Anna Bajra Shri Anna Kuttu Ram dana Kangni Kutni Kutki Kodu Cheena and Samaa said Finance Minister Nirmala Sitharaman.Millets went out of favour and down the order in the common mans kitchen when many food conglomerates driven by profits and not by the desire to help improve the health standards of people prioritised other grains over millets.India like many other countries witnessed a major decline in both production and consumption of millet.\n",
      "They have been a large contributor to Indians balanced diets.The Government of India has identified millet as a safe bet to enhance farmers income and as a reliable grain to ensure Indias nutritional and food security.We are the largest producer and the second largest exporter of Shri Anna Millets in the world.\n",
      "==========================\n",
      "Summary for Document 2\n",
      "\n",
      "\n",
      "The Millets And Other Ancient GRains International ReSearcH Initiative MAHARISHI is also proposed for deliberations as a G20 initiative during Indias presidency an official statement said.\n",
      "A threeday Meeting of Agricultural Chief Scientists MACS under Indias G20 presidency will kickstart on Monday in Varanasi and will discuss on sustainable agriculture and food systems for healthy people and planet.\n",
      "Agriculture research and development including food security and nutrition climate smart agriculture digital agriculture public private partnership etc.\n",
      "==========================\n",
      "Summary for Document 3\n",
      "\n",
      "\n",
      "Union Agriculture Minister Narendra Singh Tomar on Friday said the government is making efforts to boost the production and consumption of millets.\n",
      "We are making efforts to enhance production yield processing and consumption of millers in the country Tomar said.\n",
      "Cooperative NAFED in collaboration with the agriculture ministry established this centre to create awareness about the benefits of millet and encourage its adoption among the general public.\n",
      "==========================\n",
      "Summary for Document 4\n",
      "\n",
      "\n",
      "FSSAI has referred the matter to licensing authorities concerned to issue notices to these FBOs for withdrawing misleading claims or scientifically substantiate claims.\n",
      "Food regulator FSSAI on Friday said there are 32 new cases where food business operators FBOs have been primafacie found in violation of misleading advertisements and claims.\n",
      "Under these regulations deceptive claims or advertisements are prohibited and are punishable offences under Section53 of the FSS Act 2006.\n",
      "==========================\n",
      "Summary for Document 5\n",
      "\n",
      "\n",
      "The business requires a new set of skills distribution product development sales and marketing Karthik Jayaraman Managing Director WayCool Foods told reporters here on Friday.We will be doubling the revenue this year to Rs 800 crore by expanding our reach and launching new products.\n",
      "The business needs a focused approach and dedicated manpower to grow it.Last year the revenue from the hived off brands  Kitchenji dals staples and spices Madhuram bulk grain and pulse Fresheys readytocook items dairy products  was about Rs 400 crore.\n",
      "We will be present in all the south Indian towns having a population of about 30000 people said BP Ravindran CEO of WayCool BrandsNext the new subsidiary.Ravindran said the company will soon launch a health mix powder with higher millet content and also come out with milletbased food products.Discover the stories of your interestBlockchain5 StoriesCybersafety7 StoriesFintech9 StoriesEcomm9 StoriesML8 StoriesEdtech6 StoriesAgreeing that postCovid people are looking at healthier food options Ravindran said the company will also come out with various rice varieties like redbrown and others and valueadded dairy products.According to Jayaraman the demand for whitelabelled products have gone up and the company is also serving the needs of companies that are into delivering groceries to homes.The parent company WayCool Foods is largely a businesstobusiness B2B food products supplier sourcing from farmersfarmer producer organisations directly and supplying to retail outletsbulk buyers in the southern markets and in Maharashtra.WayCool Indias leading food and agritech company has signed a Memorandum of Understanding MoU with Central Warehousing Corporation CWC to bolster the distribution of its agriinput portfolio.\n",
      "==========================\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import TfidfModel, LsiModel\n",
    "\n",
    "\n",
    "\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "# Preprocess the text data\n",
    "\n",
    "if len(doc_complete) >= 2:\n",
    "    doc_complete.pop(1)\n",
    "\n",
    "# Define stopwords and lemmatizer\n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to preprocess a document\n",
    "def preprocess_document(document):\n",
    "    \n",
    "    # Split the document into sentences\n",
    "    sentences = sent_tokenize(document)\n",
    "    \n",
    "    # Preprocess each sentence\n",
    "    preprocessed_sentences = []\n",
    "    for sentence in sentences:\n",
    "        # Tokenize the sentence\n",
    "        tokens = word_tokenize(sentence.lower())\n",
    "        \n",
    "        # Remove stopwords and punctuation\n",
    "        tokens = [token for token in tokens if token.isalpha() and token not in stopwords]\n",
    "        \n",
    "        # Lemmatize the tokens\n",
    "        tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "        \n",
    "        preprocessed_sentences.extend(tokens)\n",
    "    \n",
    "    return preprocessed_sentences\n",
    "\n",
    "# Create a list of preprocessed documents\n",
    "preprocessed_documents = [preprocess_document(doc) for doc in doc_complete]\n",
    "\n",
    "# Flatten the list of tokens\n",
    "flattened_documents = [token for document in preprocessed_documents for token in document]\n",
    "\n",
    "# Create a dictionary of terms\n",
    "dictionary = Dictionary([flattened_documents])\n",
    "corpus = [dictionary.doc2bow(doc) for doc in preprocessed_documents]\n",
    "\n",
    "# Create a TF-IDF model\n",
    "tfidf = TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "\n",
    "# Apply LSA\n",
    "lsa_model = LsiModel(corpus_tfidf, id2word=dictionary, num_topics=20)  # Adjust the number of topics as needed\n",
    "\n",
    "# Generate summaries\n",
    "for i, doc in enumerate(preprocessed_documents):\n",
    "    bow = dictionary.doc2bow(doc)\n",
    "    doc_topics = lsa_model[bow]\n",
    "    doc_topics_sorted = sorted(doc_topics, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Extract top sentences as summary\n",
    "    top_sentences = [sent_tokenize(doc_complete[i])[j] for j, _ in doc_topics_sorted[0:3]]  # Extract top 3 sentences from the original document\n",
    "    \n",
    "    # Print the summary\n",
    "    print(\"Summary for Document\", i+1)\n",
    "    print(\"\\n\")\n",
    "    print(\"\\n\".join(top_sentences))\n",
    "    generated_summaries.append(\"\".join((top_sentences)))\n",
    "    print(\"==========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "86ba49d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generated_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a230e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Reference_summaries = list(doc_complete)\n",
    "Generated_summaries = list(generated_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23097527",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Reference_summaries[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65f51085",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generated_summaries[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "82f71df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score for Summary 1 : 0.08135100400101479\n",
      "BLEU score for Summary 2 : 0.002747182871391865\n",
      "BLEU score for Summary 3 : 0.0017575743437884257\n",
      "BLEU score for Summary 4 : 0.017289883619560634\n",
      "BLEU score for Summary 5 : 0.6672570576716137\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "bleu_scores = []\n",
    "for ref, gen in zip(Reference_summaries, Generated_summaries):\n",
    "    bleu_score = sentence_bleu([ref], gen)\n",
    "    bleu_scores.append(bleu_score)\n",
    "\n",
    "# Print BLEU score for each summary\n",
    "for i, score in enumerate(bleu_scores):\n",
    "    print(\"BLEU score for Summary\", i+1, \":\", score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37d1c45",
   "metadata": {},
   "source": [
    "- Summary 1 has a BLEU score of 0.0814, indicating a relatively low similarity to the reference summaries. The generated summary captures some aspects but lacks significant overlap with the reference summaries.\n",
    "\n",
    "\n",
    "- Summary 2 has a very low BLEU score of 0.00275, indicating a minimal overlap with the reference summaries. The generated summary does not capture the content or structure of the reference summaries effectively.\n",
    "\n",
    "\n",
    "- Summary 3 has a similarly low BLEU score of 0.00176, indicating a lack of meaningful similarity to the reference summaries. The generated summary does not capture the key information or context present in the reference summaries.\n",
    "\n",
    "\n",
    "- Summary 4 has a slightly higher BLEU score of 0.0173, suggesting a bit more overlap with the reference summaries compared to the previous summaries. However, the generated summary still falls short in capturing the main points and details of the reference summaries.\n",
    "\n",
    "\n",
    "- Summary 5 stands out with a relatively high BLEU score of 0.6673. This indicates a significant overlap and similarity to the reference summaries. The generated summary captures the essence and key information from the reference summaries effectively.\n",
    "\n",
    "\n",
    "__In summary, based on the BLEU scores, Summary 5 appears to be the most coherent and accurate among the generated summaries, while the other summaries lack substantial similarity and fail to fully represent the reference summaries__."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
